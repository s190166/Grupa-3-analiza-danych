---
title: "Projekt - Analiza Danych - grupa 3"
author: "Zuzanna Łomża, Zuzanna Łebed, Michał Książek"
date: "2024-12-05"
output:  rmdformats::readthedown
---

```{r setup1, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
data <- read.csv("supermarket_new (1).csv")
library(rmdformats)
library(naniar)
library(reshape2)
library(ggplot2)
library(rstatix)
library(ggcorrplot)
library(mice)
library(validate)
library(DT)
library(lubridate)
library(ggstatsplot)
library(kableExtra)
library(tidyr)
library(plotly)
library(devtools)
library(dplyr)
library(gridExtra)
library(knitr)
library(moments)
```
<style>
    pre, code  {
    font-family: 'Arial', monospace;
    font-size: 14px;
  }
  .output {
    font-family: 'Arial', monospace;
    font-size: 14px;
}
</style>

# 1. Informacje wstępne.

<pre>
    Zbiór danych poddany analizie dotyczy historycznych sprzedaży supermarketów Biedronka, które zostały
zarejestrowane w trzech różnych oddziałach przez trzy pierwsze miesiące 2019 roku (1.01.2019-30.03.2019). 
Zmienne uwzglednione w zbiorze to: 
  - 'Invoice.ID': Numer identyfikacyjny faktury sprzedaży wygenerowany komputerowo; 
  - 'Branch': Oddział supercentrum A, B i C; 
  - 'City': Lokalizacja supercentrów w miastach Naypyitaw, Yangon i Mandalay;
  - 'Customer.type': Typ klientów, zarejestrowanych jako "członek" ("Member") dla klientów korzystających 
    z karty członkowskiej i "normalny" ("Normal") dla klientów nie posaidających karty członkowskiej; 
  - 'Gender': Płeć klienta- kobieta ("Female") i mężczyzna ("Male"); 
  - 'Product.line': Ogólne grupy kategoryzacji przedmiotów - Akcesoria elektroniczne ("Electronic 
    accessories"), Akcesoria modowe ("Fashion accessories"), Żywność i napoje ("Food and beverages"), 
    Zdrowie i uroda ("Health and beauty"), Dom i styl życia ("Home and lifestyle"), Sport i podróże 
    ("Sports and travel"); 
  - 'Unit.price': Cena każdego produktu w $; 
  - 'Quantity': Liczba produktów zakupionych przez klienta; 
  - 'Tax.5.': Opłata podatkowa w wysokości 5% dla klienta dokonującego zakupu;
  - 'Total': Całkowita cena z 5% podatkiem;
  - 'Date': Data zakupu (rekord dostępny od stycznia 2019 r. do marca 2019 r.); 
  - 'Time': Czas zakupu (od 10:00 do 21:00); 
  - 'Payment': Płatność wykorzystana przez klienta do zakupu (dostępne są 3 metody - gotówka ("Cash"), 
    karta kredytowa ("Credit card") i portfel elektroniczny ("Ewallet"); 
  - 'cogs': Koszt sprzedanych towarów; 
  - 'gross.margin.percentage': Procentowa marża brutto; 
  - 'gross.income': Dochód brutto; 
  - 'Rating': Ocena stratyfikacji klientów dotycząca ich ogólnego doświadczenia zakupowego 
    (w skali od 1 do 10).
</pre>

# 2. Analiza brakujacych obserwacji.

<pre>
Zbiór danych zawiera `r n_miss(data)` brakujących wartości.
</pre>

### Tabela podsumowująca braki

```{r Tabela_podsumowująca_liczbę_NA, echo=FALSE, paged.print=TRUE, results='asis'}
datatable<- data
datatable(miss_var_summary(data))
```

<pre>
    Powyższa tabela wskazuje rozłożenie brakujących wartości w zbiorze. Największa liczba braków dotyczy kolumn
'gross.income' oraz 'Rating', w których znajdowało się po 150 liczb NA. W kolumnie 'City' natomiast, braki stanowiły 
10% wszystkich obserwacji dla tej zmiennej.
</pre>

### Wizualizacja lokalizacji braków

```{r Shadow map, echo=FALSE}
vis_miss(data, sort = TRUE)
```

<pre>
    Wizualizacja prezentująca lokalizację braków w zbiorze skłania ku stwierdzeniu, że pojawiające się wartości NA
są rozmieszczone w sposób losowy, bez wyraźnych wzorców grupowania się w określonych obszarach zbioru.
    Ponadto braki te stanowią 2,9% wszystkich obserwacji, co wskazuje na ich stosunkowo niewielką liczbę.
</pre>

### Współwystępowanie braków

```{r Wykres UpSet dla współwystępowania NA, echo=FALSE}
gg_miss_var(data)

gg_miss_upset(data, 
              nsets = 3)
```

<pre>
    W celu dokładniejszej analizy stworzono wykres UpSet, który prezentuje współwystępowanie braków między
zmiennymi. Wynika z niego, że:
  - dla zmiennej 'gross.income' 116 braków (ok. `r round(116/150*100, 2)`%) występuje niezależnie od innych zmiennych z brakującymi 
    wartościami. Ponadto 20 braków współwystępuje ze zmienną 'Rating', 13 ze zmienną 'City', a 1 przypadek 
    braku dotyczy wszystkich trzech zmiennych jednocześnie;
  - zmienna 'Rating' posiada 113 braków (ok. `r round(113/150*100, 2)`%) niezależnych oraz 16 przypadków współwystępujących 
    ze zmienną 'City';
  - zmienna 'City', poza wskazanymi zależnościami, posiada 70 braków (`r 70/100*100`%), które nie występują równocześnie 
    w innych rekordach.
    Podsumowując, w analizowanym zbiorze braki najczęściej występują osobno w poszczególnych kolumnach
(`r 116+113+70` przypadków NA), ale istnieje określona liczba przypadków, w których braki te współwystępują w dwóch 
(`r 20+16+13` przypadków NA) lub trzech kolumnach (1 przypadek NA). Sugerować to może, że występuje pewna zależność 
między brakami w analizowanych zmiennych, jednak przez wzgląd na ich niewielką liczbę w stosunku do całkowitej
liczby braków (`r (20+16+13+1)/400*100`%) – mogą być to braki, których występowanie odpowiadać może przypadkowi.

    W celu zweryfikowania tej hipotezy, przeprowadza się dalszą analizę obserwacji brakujących.
</pre>

```{r Mapa NA, echo=FALSE}
datatable(md.pattern(data, rotate.names = TRUE), width = .01, height = .01, list(rows = 0, cols = 0))
```

<pre>
    Mapa występowania braków odzwierciedla wskazane przez wykres UpSet zależności. Dodatkowo odczytać z niej 
można, że w 651 wierszach w zbiorze nie występują żadne braki. W pozostałych 349 rekordach pojawiają się 
pojedyncze, podwójne oraz potrójne wartości NA, co zostało wykazane powyżej.
</pre>

### Macierz korelacji braków

<pre>
    Aby sprawdzić zależności pomiędzy brakującymi obserwacjami a wartościami pozostałych zmiennych, sporządza
się <strong>macierz korelacji braków</strong>. 
    
    W <strong>macierzy korelacji braków</strong> kolumny i wiersze reprezentują zmienne ze zbioru, a wartości w macierzy
odpowiadają współczynnikom korelacji między wskaźnikami braków (zmiennymi binarnymi oznaczającymi
obecność braków) lub między wskaźnikami braków a wartościami innych zmiennych. Na jej podstawie można
określić, czy wartości brakujące pojawiają się losowo (MCAR, <em>Missing Completely at Random</em>), 
czy w przypadku silnych korelacji ich występowanie zależy od innych zmiennych (MAR, <em>Missing at Random</em>). 

<span style="font-family: "Times New Roman", Times, serif;">W celu jej utworzenia, wyróżnia się następujące etapy:
  I. Sprawdzenie struktury danych w zbiorze.
  II. Przekodwoanie wskazanych zmiennych jakościowych na ilościowe.
  III. Obliczenie korelacji między brakami a zmiennymi ze zbioru.
  IV. Wygenerowanie <strong>macierzy korelacji braków</strong>.</span>
</pre>

##### Etap I. Sprawdzenie struktury danych w zbiorze.

```{r Sprawdzenie struktury danych w zbiorze, echo=FALSE}
datatable(data.frame(class = sapply(data, class)))
```

<pre>
    Tabela prezentuje strukturę zmiennych w zbiorze. Ich analiza jest konieczna, aby móc dokonać przekształceń 
zmiennych jakościowych (<em>character</em>) na zmienne ilościowe (<em>numeric</em>, <em>integer</em>) i przejść do etapu obliczania korelacji 
między brakami a zmiennymi. Wybrane zmienne do przekodowania to:
  - 'Ivioice.ID'
  - 'Branch'
  - 'City'
  - 'Customer.type'
  - 'Gender'
  - 'Product.line'
  - 'Date'
  - 'Time'
  - 'Payment'.
</pre>

##### Etap II. Przekodwoanie wskazanych zmiennych jakościowych na ilościowe.

```{r Przekodowanie zmiennych jakościowych na ilościowe, echo=FALSE}
data2 <- data.frame(data, row.names = TRUE)

data2$Branch <- ifelse((data2$Branch) == "A", 1, 
                       ifelse(data2$Branch == "B", 2, 0))

data2$City <- ifelse(is.na(data2$City), NA, ifelse(data2$City == "Naypyitaw", 1,
                                                   ifelse(data2$City == "Mandalay", 2, 0)))

data2$Customer.type <- ifelse((data2$Customer.type) == "Member", 1, 0)

data2$Gender <- ifelse((data2$Gender) == "Male", 1, 0)

data2$Product.line <- ifelse(data2$Product.line == "Electronic accessories", 1,
                             ifelse(data2$Product.line == "Fashion accessories", 2,
                                    ifelse(data2$Product.line == "Food and beverage", 3,
                                           ifelse(data2$Product.line == "Health and beauty", 4,
                                                  ifelse(data2$Product.line == "Sports and travel", 5, 0)))))

data2$Payment <- ifelse(data2$Payment == "Cash", 1, 
                        ifelse(data2$Payment == "Credit card", 2, 0))

data2$Date <- as.Date(data2$Date, format = "%m/%d/%Y")
data2 <- data2 %>%
  mutate(Date = month(Date))

data2$Time <- as.numeric(sub(":(\\d{2}):.*", ".\\1", data2$Time))

```

<pre>
Na etapie przekodowania zmiennych, dokonano przekształcenia:
  - na zmienne binarne (0,1): 'Customer.type' oraz 'Gender';
  - na zmienne wielokategorialne (w zakresie 0-5): 'Branch' (0,1,2), 'City' (0,1,2), 'Product.line' (0,1,2,3,4,5)
    i 'Payment' (0,1,2).
      
    Ponadto przypisano zmiennej określającej datę zakupu towaru ('Date') odpowiadające jej numery miesiąca (1,2,3),
w celu wydobycia z niej możliwie istotnych informacji (np. konkretny wzorzec występowania braków) oraz przypisano 
zmienną 'Invoice.ID' do nazw wierszy, przez wzgląd na jej niewielką wartość informacyjną.
</pre>

##### Etap III. Obliczenie korelacji między brakami a zmiennymi ze zbioru.

```{r Korelacja braków, echo=FALSE}
NA_cor <- cor_mat(data2)
```

<pre>
    Po utowrzeniu zmiennej binarnej (0,1) reprezentującej wskaźnik braków, gdzie 1 oznacza brak wartości, 
a 0 - jej obecność, obliczono wartość korelacji między danymi wskaźnikami oraz wskaźnikami i wartościami
innych zmiennych.
</pre>

```{r Wykluczanie zmiennej gross.margin.percentage, echinclude=FALSE}
data_cor <- data2 %>% mutate(gross.margin.percentage = NULL)

NA_cor2 <- cor_mat(data_cor)
```

<pre>
    Dla 'gross.margin.percentage' korelacja nie mogła zostać policzona, ze względu na powtarzające sie wartości tej 
zmiennej w każdym kolejnym wierszu, wynikiem czego korelacja skutkowała nieprawidłową wartością `r unique(NA_cor$gross.margin.percentage)`. Z tego
względu zmienna ta została wykluczona z analizy korelacji, w celach dalszej wizualizacji korelacji braków.
</pre>

##### Etap IV. Wygenerowanie <em>macierzy korelacji braków</em>.

```{r Macierz korelacji braków, echo=FALSE}
ggcorrplot(NA_cor2)
```

<pre>
    Macierz korelacji braków przedstawiona na wizualizacji wskazuje na istnienie bardzo silnej, dodatniej korelacji między 
wartościami brakującymi a wartościami zmiennych: 'Total', 'Tax.5.', 'cogs' oraz 'gross.income' i silnej, dodatniej korelacji
wartości zmiennych: 'cogs', 'Unit.price', 'Quantity' i 'gross.income'. Ponadto zaobserwowano istotną korelację
dodatnią dla zmiennych 'Branch' i 'City'.
    Wyniki te oznaczają, że jeśli jedna ze wskazanych zmiennych posiada brakującą wartość, istnieje duże 
prawdopodobieństwo, że pozostałe zmienne również będą zawierać brakujące obserwacje. 
    To z kolei sugeruje, że w przypadku zmiennych o charakterze finansowym, takie braki mogą być losowe (MAR), 
zależne od innych wartości, lub jeśli wartości były celowo pomijane - nielosowe (NMAR), niezależne od pozostałych 
zmiennych. 
    Natomiast w przypadku zmiennych dotyczących lokalizacji sklepów, bardziej prawdopodobne jest, że braki
w zmiennej 'City' mają charakter losowy (MAR). Wynika to z faktu, że konkretna lokalizacja jest powiązana
z danym oddziałem sklepu ('Branch'), więc brak informacji o mieście wynikać może z wcześniej podanej informacji 
o oddziale.
    Dodatkowo, braki w zmiennej 'Rating' nie wykazują żadnych zależności z innymi wartościami zmiennych. Na tej 
podstawie można przypuszczać, że są to braki typu MCAR i zasadnym jest zastosowanie prostej imputacji danych.
</pre>

### Sprawdzenie zależności występowania braków w zmiennej 'gross.income'

<pre>
    W celu sprawdzenia mechanizmu występowania wartości brakujących w zmiennej 'gross.income' oraz dobrania 
do niej odpowiedniej formy imputacji, należy dokonać analizy wykazanych zależności z wartościami zmiennych 
'Total', 'Tax.5.', 'cogs' oraz 'Quantity' i 'Unit.price'.
    Występowanie korelacji pomiędzy wymienionymi zmiennymi można wyjaśnić w prosty sposób, biorąc pod uwagę
definicję wskazanych zmiennych i ich odzwiercielenie faktycznych wartości finansowych. 
</pre>

```{r Sprawdzenie wartości zmiennych, echo=FALSE}
results1 <- data.frame(
  Warunek = c(
    "Czy koszt sprzedanych produktów jest równy iloczynowi ilości sprzedanych produktów i kosztowi jednostkowemu produktu (przychodom ze sprzedaży)?",
    "Czy opłata podatkowa od sprzedaży (5%) jest równa iloczynowi kosztu sprzedanych towarów i 5% podatku?",
    "Czy całkowita kwota do zapłaty przez klienta z uwzglenieniem podatku jest równa sumie kosztów sprzedanych towarów i opłacie podatkowej (5%)?",
    "Czy dochód brutto za sprzedane towary jest równy różnicy całkowitej kwoty do zapłaty z podatkiem i kosztów sprzedanych towarów?"
  ),
  Wynik = c(
    ifelse(all(data$cogs == data$Quantity * data$Unit.product), "TAK", "NIE"),
    ifelse(all(round(data$Tax.5., 4) == round(data$cogs * 0.05, 4)), "TAK", "NIE"),
    ifelse(all(round(data$Total, 4) == round(data$cogs + data$Tax.5., 4)), "TAK", "NIE"),
    ifelse(all(round(data$gross.income, 4) == round(data$Total - data$cogs, 4) | is.na(data$gross.income)), "TAK", "NIE")
  )
)

datatable(results1, options = list(dom = 't', paging = FALSE))

```

<pre>
Analiza wartości tych zmiennych wykazuje, że:
  - zmienna 'cogs' mówiąca o koszcie wytworzenia sprzedanych towarów jest równa przychodowi ze sprzedaży, a co 
    za tym idzie - iloczynowi ilości sprzedanych produktów ('Quantity') i kosztowi jednostkowemu produktu ('Unit.price'):
    <em>'cogs' = 'Quantity' * 'Unit.price'</em>;
  - zmienna 'Tax.5.' mówiąca o opłacie podatkowej od sprzedaży w wysokości 5% jest równa iloczynowi kosztu
    sprzedanych towarów ('cogs') i 5% podatku:
    <em>'Tax.5. = 'cogs' * 5%</em>;
  - zmienna 'Total' mówiąca o całkowitej kwocie do zapłaty przez klienta za pojedynczą fakturę, z uwzglenieniem
    podatku jest równa sumie kosztów sprzedanych towarów ('cogs') i opłacie podatkowej w wysokości 5% ('Tax.5.'):
    <em>'Total' = 'cogs' + 'Tax.5.'</em>;
  - zmienna 'gross.income' mówiąca o dochodzie brutto (zysku) za sprzedane towary, która w rzeczywistości
    odzwierciedla różnicę przychodów ze sprzedaży i kosztu sprzedanych produktów, w zbiorze danych jest
    równowartością różnicy całkowitej kwoty do zapłaty z podatkiem ('Total') i kosztów wytworzenia sprzedanych
    produktów ('cogs'):
    <em>'gross.income' = 'Total' - 'cogs'</em>
Jeśli zatem <em>'Total' = 'cogs' + 'Tax.5.'</em>, to <em>'gross.income' = ('cogs' + 'Tax.5.') - 'cogs' = 'Tax.5.'</em>

    Tę zależność potwierdza poniższa wizualziacja.
</pre>

```{r Porównanie rozkładów gross.income i Tax.5., echo=FALSE, warning=FALSE}
data_long <- data %>%
  pivot_longer(cols = c(gross.income, Tax.5.), names_to = "Zmienna", values_to = "Wartość")

ggplot(data_long, aes(x = Wartość, fill = Zmienna)) +
  geom_histogram(alpha = 0.5, bins = 30, position = "identity") +
  scale_fill_manual(values = c("gross.income" = "#e71d36", "Tax.5." = "#f8ad9d")) +
  labs(
    title = "Porównanie rozkładów gross.income i Tax.5.",
    subtitle = "Z pominięciem 150 wierszy z brakującymi wartościami dla zmiennej 'gross.income'",
    x = "Wartość",
    y = "Częstość",
    fill = "Zmienna"
  )
```

<pre>
    Histogram przedstawia porównanie rozkładów zmiennych 'gross.income' oraz 'Tax.5.'. Obie zmienne są nałożone
na siebie, w celu umożliwienia bezpośredniego porównania ich kształtu i rozkładu. Ze zbioru obserwacji zmiennej
'gross.income' wykluczono 150 obserwacji brakujących, co nieznacznie zaniża jej rozkład. Zauważyć jednak można,
że dla obu zmiennych, wartości obserwacji skupiają sie w zakresie 0-25, czyniąc je prawostronnie skośnymi. 
Ponadto obserwowalna jest zależność, w której częstość występowania danych wartości dla obu zmiennych 
odzwierciedla niemalże identyczny kształt rozkładu, z wysokimi i niskimi częstościami w tych samych przedziałach.

    W związku z powyższą analizą dotyczącą zależności między brakami zmiennej 'gross.inocme' a zmiennymi 'Total', 
'Tax.5.' oraz 'cogs' można wyciągnąć wniosek, że związek wartości 'gross.income' z wartościami pozostałych
zmiennych wynika z finansowych powiązań między nimi. Dodatkowo, można przyjąć, że wartości zmiennej 
'gross.income' odpowiadają wartościom zmiennej Tax.5. i zasadnym jest zastosowanie imputacji poprzez 
zastąpienie wartości brakujących obserwacjami pełnowartościowej zmiennej.
</pre>

### Sprawdzenie zależności występowania braków w 'City' od zmiennej 'Branch'

```{r Wykres braków w City według oddziału, echo=FALSE}

City_info <- ifelse(is.na(data$City), "Brak informacji o 'City'", "Podana informacja o 'City'")

ggplot(data, aes(x = Branch, fill = City_info)) +
  geom_bar(position = "fill") + 
  geom_text(
    aes(label = scales::percent(after_stat(count)/ sum(after_stat(count)))), 
    stat = "count", position = position_fill(vjust = 0.5)
  ) +
  labs(y = "%", title = "Procent braków w 'City' dla każdego oddziału ('Branch')") +
  scale_fill_manual(values = c("Brak informacji o 'City'" = "#bfd7ff", "Podana informacja o 'City'" = "#788bff")) +
  theme_minimal()
```

<pre>
    Aby lepiej zrozumieć zależność między wartościami brakujacymi w zmiennej 'City' a wartościami zmiennej 'Branch'
sporządzono powyższy wykres słupkowy. Wskazuje on, że braki w każdym z oddziałów ('Branch') są rozłożone
równomiernie (wynoszą ok. `r mean(3.5, 2.8, 3.7)`%), z niewielkimi odchyleniami (ok. `r round(sd(c(3.5, 2.8, 3.7)), 2)`p. %). Może to świadczyć o tym, że braki 
nie są zależne od konkretnych oddziałów.
</pre>

```{r Test chi^2 dla City i Branch, echo=FALSE}
City_table <- table(City_info, data$Branch)

chi2_City_NA <- chisq.test(City_table)

as.data.frame(City_table) %>%
  pivot_wider(names_from = Var2, values_from = Freq, values_fill = 0) %>%
  datatable(,  options = list(paging = FALSE, searching = FALSE, info = FALSE))

chi2 <- chi2_City_NA$statistic
p <- chi2_City_NA$p.value
parametr <- chi2_City_NA$parameter

chi2_City_NA <- data.frame(
  Statistic = round(chi2, 2),
  p_value = round(p, 2),
  df = round(parametr, 2))

chi2_City_NA %>%
  kable("html", caption = "Wynik testu chi-kwadrat", align = 'c') %>%
  kable_styling(
    bootstrap_options = c("striped", "hover", "condensed", "responsive"),
    full_width = FALSE,
    html_font = "Arial",
    font_size = 15
  )
```

<pre>
    W ramach sprawdzenia zależności braków zmiennej 'City' od zmiennej 'Branch' wykonano nieparametryczny test 
zależności chi2. Hipotezy dla tesu brzmiały następująco:

    H0: <em>Braki w 'City' są niezależne od zmiennej 'Branch'.</em>
    HA: <em>Braki w 'City' są zależne od zmiennej 'Branch'.</em>
    
    Statystyka chi2 równa 1,54 przy wartości p-value (0,46) większej od przyjętego poziomu istotności (0,05) wykazała, 
że nie ma podstaw do odrzucenia H0 mówiącego o niezależności braków obserwacji zmiennej 'City' od wartości 
zmiennej 'Branch'. 
    Wobec tego, można wskazać, że braki występujące w zmiennej 'City' nie mają statystycznie istotnej zależności 
i można zastosować dla nich prostą imputację danych.
</pre>

### PODSUMOWANIE ANALIZY BRAKUJĄCYCH OBSERWACJI

<pre>
    Z powyższej analizy dotyczącej obserwacji brakujących w zbiorze danych dotyczącym sprzedaży w trzech sklepach
Biedronka wynika, że wartości NA występują w trzech zmiennych: 'gross.income' (150 przypadków braków), 'Rating'
(150 przypadków braków) oraz 'City' (100 przypadków braków).

    Przedstawione wizualizacje oraz testy wykazały, że braki te najprawdopodobniej są losowe (MAR) lub kompletnie
losowe (MCAR) w przypadku zmiennej finansowej 'gross.income' oraz zmiennej dotyczącej lokalzacji 'City' i kompletnie
losowe (MCAR) w przypadku zmiennej 'Rating'. 
    W zwiazku z tym, zaleca się stosowanie prostej imputacji danych polegającej na uzupełnieniu brakujących wartości 
w zmiennej 'gross.income' wartościami ze zmiennej 'Tax.5.', przypisaniu brakującym wartościom zmiennej 'City'
odpowieniej nazwy miasta w oparciu o oddział 'Branch', jaki jest mu przypisany oraz zastosowaniu np. średniej
lub mediany w uzupełnieniu zmiennej 'Rating', bądź uzupełnianiu jej poprzez wielokrotną imputację, przy pomocy
pakietu "mice" (<em>Multiple Imputation by Chained Equations</em>).
</pre>

# 3. Walidacja danych.

<pre>
    W celu sprawdzenia, czy wartości w zbiorze danych spełniają określone krytera dla zmiennych, których poprawne
zachowanie jest niezbędne do dalszej analizy, obejmującej m.in. imputację, wizualizację, wnioskowanie statatystyczne
i testowanie, stosuje się <strong>walidację danych</strong>. 
    Proces ten polega na definiowaniu reguł, jakie muszą spełnić zmienne w zbiorze, a następnie sprawdzenie, czy
występują w nim jakiekolwiek nieprawidłowości w postaci "brudnych" danych. Jeżeli analiza wykaże obecność takich
wartości, kolejnym etapem jest "czyszczenie" zbioru. Może to obejmować poprawę danych (np. dopasowanie
do prawidłowego formatu) lub usunięcie informacji, które są nieistotne dla badania, a mogą zakłócać działanie
programu i proces dalszej analizy. 
</pre>

### Sprawdzanie ppoprawności danych zależnych

```{r Dodawanie zmiennych pomocniczych, include=FALSE}
check_cogs <- data$Quantity * data$Unit.price %>%
              as.data.frame()
check_Tax.5. <- .05 * data$cogs %>%
                as.data.frame()
check_Total <- data$Tax.5. + data$cogs %>%
               as.data.frame()
check_gross.income <- data$Total - data$cogs %>%
                      as.data.frame()
```

```{r Definowanie reguł, echo=FALSE}
rules <- validator(if (City == "Yangon") Branch == "A",
                   if (City == "Mandalay") Branch == "B",
                   if (City == "Naypyitaw") Branch == "C",
                   Tax.5. == check_Tax.5.,
                   Total == check_Total,
                   cogs == check_cogs,
                   gross.income == check_gross.income,
                   Unit.price >= 0,
                   Quantity >= 0,
                   gross.margin.percentage >= 0,
                   Rating >= 1,
                   Rating <= 10)
```

<pre>
    Dla analizowanego zbioru danych zdefiniowano reguły walidacyjne, dla wybranych zmiennych zależnych
jakościowych i ilościowych, których nieprawidłowości mogłyby mieć istotny wpływ w dalszej analizie.

Określone reguły przedstawia się następująco:
</pre>

```{r Reguły - tabelka, echo=FALSE}
reguly <- data.frame(
  LP = 1:12,
  Reguła = c(
    "Jeśli lokalizacja sklepu ('City') to 'Yangon', odpowiadający mu oddział ('Branch') to oddział 'A'.",
    "Jeśli lokalizacja sklepu ('City') to 'Mandalay', odpowiadający mu oddział ('Branch') to oddział 'B'.",
    "Jeśli lokalizacja sklepu ('City') to 'Naypyitaw', odpowiadający mu oddział ('Branch') to oddział 'C'.",
    "Opłata podatkowa od sprzedaży w wysokości 5% ('Tax.5.') jest równa iloczynowi kosztu sprzedanych towarów ('cogs') i 5% podatku.",
    "Całkowita kwota do zapłaty przez klienta za pojedynczą fakturę z uwzględnieniem 5% podatku ('Total') jest równa sumie kosztów sprzedanych towarów ('cogs') i opłacie podatkowej w wysokości 5% ('Tax.5.').",
    "Koszt wytworzenia sprzedanych towarów jest równy iloczynowi ilości sprzedanych produktów ('Quantity') i kosztowi jednostkowemu produktu ('Unit.price').",
    "Dochód brutto za sprzedane towary ('gross.income') jest równy różnicy całkowitej kwoty do zapłaty z 5% podatkiem ('Total') i kosztów wytworzenia sprzedanych produktów ('cogs').",
    "Cena jednostkowa produktu ('Unit.price') jest równa lub wyższa od 0.",
    "Ilość sprzedanych produktów ('Quantity') jest równa lub wyższa od 0.",
    "Procentowa marża brutto ('gross.margin.income') jest równa lub wyższa od 0.",
    "Ocena stratyfikacji klientów dotycząca ich ogólnego doświadczenia zakupowego jest równa lub większa od 1.",
    "Ocena stratyfikacji klientów dotycząca ich ogólnego doświadczenia zakupowego jest równa lub mniejsza od 10."
  )
)

datatable(reguly, options = list(dom = 't', paging = FALSE), rownames = FALSE)
```

```{r Wizualizacja braków oraz błędów według reguł, echo=FALSE}
cf <- confront(data, rules) %>%
      barplot(main="Wyniki walidacji danych według reguł") %>%
      suppressWarnings()
```

<pre>
    Powyższa wizualizacja wskazuje, że w analizowanym zbiorze danych nie występują nieprawidłowości w postaci 
"brudnych" wartości w zmiennych zależnych o określonych regułach.
</pre>

### Sprawdzenie poprawności zmiennych kategorycznych

```{r Sprawdzenie poprawności pozostałych zmiennych kategorycznych, echo=FALSE}
correct_values_Product.Line <- c("Health and beauty", "Electronic accessories", "Home and lifestyle", "Sports and travel", "Food and beverages", "Fashion accessories")
all_correct_Product.line <- all(data$Product.line %in% correct_values_Product.Line)

correct_values_Gender <- c("Female", "Male")
all_correct_Gender <- all(data$Gender %in% correct_values_Gender)

correct_values_Customer.type <- c("Normal", "Member")
all_correct_Customer.type <- all(data$Customer.type %in% correct_values_Customer.type)

correct_values_Payment <- c("Ewallet", "Cash", "Credit card")
all_correct_Payment <- all(data$Payment %in% correct_values_Payment)

results3 <- data.frame(
  Warunek = c(
    "Czy zmienna 'Product.line' posiada prawidłowe wartości?",
    "Czy zmienna 'Gender' posiada prawidłowe wartości?",
    "Czy zmienna 'Customer.type' posiada prawidłowe wartości?",
   "Czy zmienna 'Payment' posiada prawidłowe wartości?"
  ),
  Wynik = c(
    ifelse(all_correct_Product.line, "TAK", "NIE"),
    ifelse(all_correct_Gender, "TAK", "NIE"),
    ifelse(all_correct_Customer.type, "TAK", "NIE"),
    ifelse(all_correct_Payment, "TAK", "NIE")
  )
)
datatable(results3, options = list(dom = 't', paging = FALSE))
```

<pre>
    Ponadto można stweirdzić, że zbiór ten nie posiada również nieprawidłowości w postaci m.in. literówek 
w wartościach zmiennych kategorycznych.
</pre>

### Sprawdzenie występowania duplikatów rekordów

```{r Sprawdenie występowania duplikatów rekordów, echo=FALSE}
duplicates <- duplicated(data)

results2 <- data.frame(
  Reguła = "Czy zbiór posiada duplikaty wierszów?",
  Wynik = ifelse(any(duplicated(data)), "TAK", "NIE")
)

datatable(results2, options = list(dom = 't', paging = FALSE), rownames = FALSE)
```

<pre>
W zbiorze tym nie występują również duplikaty wierszów. 
</pre>

### PODSUMOWANIE WALIDACJI DANYCH

<pre>
    Z powyższej analizy dotyczącej identyfikacji nieprawidłowości w zbiorze danych dotyczącym sprzedaży w trzech 
sklepach Biedronka wynika, że wartości zmiennych są poprawne i nie wymagają poddania procesowi czyszczenia
danych (<em>Data Cleansing</em>).
</pre>

# 4. Czyszczenie danych z NA

<pre>
Poniższy kod uzupełnia brakujące wartości w kolumnach na podstawie zależności i imputacji. Kolumna `City` została uzupełniona na podstawie jednoznacznej relacji z kolumną `Branch`. Braki w kolumnie `gross income` zastąpiono wartościami z kolumny `Tax 5%`, ponieważ dane te były tożsame. Braki w kolumnie `Rating` uzupełniono za pomocą imputacji z pakietu `mice`, wykorzystując metodę dopasowania predyktywnego (`pmm`).
</pre>

```{r przygotowanie środowiska do trzyszczenia danych}

# Mapowanie relacji między Branch a City
branch_to_city <- data %>%
  filter(!is.na(City)) %>%
  distinct(Branch, City) %>%
  group_by(Branch) %>%
  summarize(City = first(City))

# Łączenie danych, aby wypełnić brakujące wartości w kolumnie City
data <- data %>%
  left_join(branch_to_city, by = "Branch", suffix = c("", ".y")) %>%
  mutate(City = ifelse(is.na(City), City.y, City)) %>%
  select(-City.y)

# Sprawdzanie liczby brakujących wartości w kolumnie City
sum(is.na(data$City))

# Sprawdzanie dostępnych kolumn
colnames(data)

# Zastępowanie brakujących wartości w kolumnie 'gross income' wartością z kolumny 9
data <- data %>%
  mutate(`gross.income` = ifelse(is.na(`gross.income`), data[[9]], `gross.income`))

# Sprawdzanie liczby brakujących wartości w kolumnie 'gross income'
sum(is.na(data$`gross.income`))

# Imputacja brakujących wartości za pomocą pakietu 'mice'
imputed_data <- mice(data, m = 1, method = "pmm", maxit = 50, seed = 123)

# Wybór ukończonego zestawu danych
data <- complete(imputed_data, 1)

# Sprawdzanie liczby brakujących wartości w całym zbiorze danych
sum(is.na(data))

```

# 5. Wartości Odstające

<pre>
Wartości odstające to obserwacje znacząco odbiegające od reszty danych, które mogą zniekształcać wyniki analiz statystycznych. Aby zminimalizować ich wpływ, przeprowadzono analizę zmiennych `Unit.price`, `Total`, `Quantity` i `Rating`.
</pre>

```{r wartości odstające}
# Rysowanie boxplotów dla wybranych zmiennych
b1 <- ggplot(data, aes(y = Unit.price)) +
  geom_boxplot() +
  labs(title = "Boxplot: Unit Price") +
  theme_minimal()

b2 <- ggplot(data, aes(y = Total)) +
  geom_boxplot() +
  labs(title = "Boxplot: Total") +
  theme_minimal()

# Rysowanie histogramów dla wybranych zmiennych
h1 <- ggplot(data, aes(x = Unit.price)) +
  geom_histogram(bins = 30, fill = "#0c4c8a") +
  labs(title = "Histogram: Unit Price", x = "Unit Price", y = "Frequency") +
  theme_minimal()

h2 <- ggplot(data, aes(x = Total)) +
  geom_histogram(bins = 30, fill = "#0c4c8a") +
  labs(title = "Histogram: Total", x = "Total", y = "Frequency") +
  theme_minimal()

# Wyświetlenie wykresów w siatce 2x2
grid.arrange(b1, b2, h1, h2, nrow = 2)
replace_outliers_with_median <- function(column) {
  Q1 <- quantile(column, 0.25, na.rm = TRUE)
  Q3 <- quantile(column, 0.75, na.rm = TRUE)
  IQR <- Q3 - Q1
  lower_bound <- Q1 - 1.5 * IQR
  upper_bound <- Q3 + 1.5 * IQR
  column[column < lower_bound | column > upper_bound] <- median(column, na.rm = TRUE)
  return(column)
}
```

<pre>
W przypadku analizowanych zmiennych „Unit Price” i „Total” zaobserwowano obecność wartości odstających.

Dla zmiennej „Unit Price” mediana wynosi około 55 dolarów, natomiast wartości maksymalne przekraczają 100 dolarów, co wskazuje na obecność wyjątkowo wysokich wartości, które znacznie przewyższają typowy zakres cen jednostkowych produktów.

Dla zmiennej „Total” mediana oscyluje w granicach 250 dolarów, podczas gdy wartość maksymalna wynosi ponad 1000 dolarów. Tak duże różnice sugerują, że pewne transakcje znacząco odbiegają od typowego poziomu całkowitych kwot zakupów.

Obecność takich wartości odstających może mieć istotny wpływ na wyniki analiz statystycznych, szczególnie w przypadku miar wrażliwych na ekstremalne wartości, takich jak średnia arytmetyczna. Aby zminimalizować ich wpływ i poprawić jakość dalszej analizy danych, wartości odstające zostały zastąpione medianą zmiennych.

Działanie to pozwala na bardziej reprezentatywną ocenę danych, co może mieć kluczowe znaczenie w kontekście analizy zachowań klientów, segmentacji rynku lub przewidywania przyszłych trendów sprzedażowych.
</pre>

```{r setup4, echo=FALSE, include=FALSE}
# Wybór kolumn numerycznych
numeric_columns <- c("Unit.price", "Total", "Quantity", "Rating")

# Funkcja do wykrywania wartości odstających
detect_outliers <- function(column) {
  Q1 <- quantile(column, 0.25, na.rm = TRUE)
  Q3 <- quantile(column, 0.75, na.rm = TRUE)
  IQR <- Q3 - Q1
  lower_bound <- Q1 - 1.5 * IQR
  upper_bound <- Q3 + 1.5 * IQR
  which(column < lower_bound | column > upper_bound)
}

# Analiza wartości odstających przed zastąpieniem
outliers_before <- lapply(data[numeric_columns], detect_outliers)
```

<pre>
Wyświetlanie wartości obstających
</pre>

```{r setup5, include=FALSE}
# Wyświetlanie wartości odstających
print(outliers_before$Total)
```

<pre>
Wartości obstające zostały zastąpione stosująć medianę.
</pre>

```{r setup6, include=FALSE}
# Zastąpienie wartości odstających medianą
replace_outliers_with_median <- function(column) {
  Q1 <- quantile(column, 0.25, na.rm = TRUE)
  Q3 <- quantile(column, 0.75, na.rm = TRUE)
  IQR <- Q3 - Q1
  lower_bound <- Q1 - 1.5 * IQR
  upper_bound <- Q3 + 1.5 * IQR
  column[column < lower_bound | column > upper_bound] <- median(column, na.rm = TRUE)
  return(column)
}

data[numeric_columns] <- lapply(data[numeric_columns], replace_outliers_with_median)

# Analiza wartości odstających po zastąpieniu
outliers_after <- lapply(data[numeric_columns], detect_outliers)

# Wyświetlenie liczby wartości odstających po zastąpieniu
cat("\nLiczba wartości odstających po zastąpieniu:\n")
sapply(outliers_after, length)

# Porównanie wartości odstających przed i po
comparison <- data.frame(
  Variable = numeric_columns,
  Outliers_Before = sapply(outliers_before, length),
  Outliers_After = sapply(outliers_after, length)
)
print(comparison)
```

<pre>
Zastąpienie wartości odstających w danych pozwala na uzyskanie bardziej reprezentatywnych wyników, eliminując wpływ skrajnych wartości, które mogą zniekształcać analizy. Dzięki temu modelowanie i wnioskowanie staje się bardziej precyzyjne, a interpretacja danych jest łatwiejsza i bardziej wiarygodna. Takie podejście pomaga lepiej uchwycić rzeczywiste zależności w analizowanej próbie.
</pre>

# 7. Statystyki opisowe

```{r Statystyki_opisowe}
statystyki <- function(x) {
  data.frame(
    "Min" = min(x, na.rm = TRUE),
    "Max" = max(x, na.rm = TRUE),
    "Kwartyl dolny" = quantile(x, 0.25, na.rm = TRUE),
    "Mediana" = round(median(x, na.rm = TRUE), 2),
    "Kwartyl górny" = quantile(x, 0.75, na.rm = TRUE),
    "Średnia" = round(mean(x, na.rm = TRUE), 2),
    "Odch. std." = round(sd(x, na.rm = TRUE), 2),
    "IQR" = round(IQR(x, na.rm = TRUE), 2),
    "Odchylenie ćwiartkowe" = round(IQR(x, na.rm = TRUE) / 2, 2),
    "Odch. std. w %" = round((sd(x, na.rm = TRUE) / mean(x, na.rm = TRUE)) * 100, 2),
    "Odch. ćwiartkowe w %" = round((IQR(x, na.rm = TRUE) / median(x, na.rm = TRUE)) * 100, 2),
    "Skośność" = round(skewness(x, na.rm = TRUE), 2),
    "Kurtoza" = round(kurtosis(x, na.rm = TRUE), 2)
  )
}
```

### Statystyki dla 'Total'wg płci

<pre>
  Tabela przedstawia statystyki zmiennej Total dla kobiet i mężczyzn. 
  Wartości minimalne i maksymalne są podobne w obu grupach, co sugeruje zbliżony zakres danych.
  Mediana i kwartyle pokazują, że kobiety osiągają nieco wyższe wartości Total niż mężczyźni
  (mediana: 272,58 vs. 244,23). Podobny trend widać w średniej, co oznacza, że ogólnie wartości
  Total są wyższe dla kobiet.

  Zmienność wyników w obu grupach jest porównywalna – wskazują na to zbliżone wartości
  odchylenia standardowego i rozstępu międzykwartylowego (IQR). 
  Skośność dodatnia (0,83 dla kobiet, 0,96 dla mężczyzn) oznacza, że rozkłady są asymetryczne w
  prawo – większość wartości jest niższa, ale pojawiają się pojedyncze wysokie obserwacje.
  Kurtoza (2,81 dla kobiet, 3,04 dla mężczyzn) sugeruje, że rozkłady mają umiarkowanie
  grubsze ogony niż rozkład normalny.
</pre>

```{r statystyki_total_income_wg_gender}
statystyki_total <- data %>%
  group_by(Gender) %>%
  summarise(across(Total, statystyki)) %>%
  unnest(cols = c(Total))
```

### Statystyki dla 'gross income' wg płci

<pre>
  Tabela przedstawia statystyki dotyczące Gross Income w podziale na płeć.
  Mediana oraz kwartyle pokazują, że kobiety osiągają nieco wyższe wartości Gross Income niż
  mężczyźni (mediana: 13,57 vs. 11,22), co znajduje odzwierciedlenie również w średniej (16,03
  vs. 14,83).

  Zmienność w obu grupach jest porównywalna – świadczą o tym podobne wartości odchylenia
  standardowego oraz rozstępu międzykwartylowego (IQR). 
  Dodatnia skośność (0,83 dla kobiet, 0,96 dla mężczyzn) sugeruje, że w obu przypadkach rozkład
  jest asymetryczny w prawo, czyli większość wartości jest stosunkowo niska, ale pojawiają się
  pojedyncze wysokie obserwacje. 
  Kurtoza (2,90 dla kobiet, 3,03 dla mężczyzn) wskazuje, że rozkład ma nieco grubsze ogony niż
  rozkład normalny, co oznacza większą liczbę wartości skrajnych.
</pre>

```{r statystyki_gross_income_wg_gender}
statystyki_income <- data %>%
  group_by(Gender) %>%
  summarise(across(gross.income, statystyki)) %>%
  unnest(cols = c(gross.income))
```

### Statystyki dla 'Rating' wg typu klienta

<pre>
  Tabela przedstawia statystyki dotyczące ocen (Rating) wystawianych przez klientów w podziale
  na typ (Normal i Member). 
  Zakres ocen w obu grupach jest identyczny (od 4,00 do 10,00). Mediana i kwartyle wskazują, że
  członkowie programu lojalnościowego (Member) wystawiają nieco wyższe oceny niż klienci zwykli
  (Normal), choć różnice są niewielkie (mediana: 7,10 vs. 7,00). Średnia również jest
  minimalnie wyższa dla członków (7,05 vs. 6,97).
  
  Rozkłady ocen w obu grupach są bardzo podobne – zarówno odchylenie standardowe, jak i rozstęp
  międzykwartylowy (IQR) mają zbliżone wartości. Skośność bliska zeru (-0,01 dla Normal, -0,02
  dla Member) oznacza, że rozkłady są niemal symetryczne. 
  Kurtoza (1,84 dla Normal, 1,83 dla Member) wskazuje na spłaszczony kształt rozkładu w
  porównaniu do rozkładu normalnego, co oznacza mniejszą liczbę skrajnych ocen.
</pre>

```{r statystyki_rating_wg_customer_type}
statystyki_rating <- data %>%
  group_by(Customer.type) %>%
  summarise(across(Rating, statystyki)) %>%
  unnest(cols = c(Rating))
```

### Statystyk dla 'Unit price' wg kategorii produktów

<pre>
  Tabela przedstawia statystyki dotyczące Unit Price (ceny jednostkowej) w podziale na
  kategorie produktów. Wszystkie kategorie mają podobny zakres cen – wartości minimalne wahają
  się od 10,08 (Sports and travel) do 10,56 (Health and beauty), natomiast maksymalne ceny są
  bardzo zbliżone i mieszczą się w przedziale 99,73–99,96.
  Mediana ceny jednostkowej jest najwyższa dla Fashion accessories (58,65) oraz Sports and
  travel (57,41), a najniższa dla Home and lifestyle (54,00). Średnie wartości są również do
  siebie zbliżone, ale najwyższą średnią cenę mają Electronic accessories (57,15), a najniższą
  Sports and travel (54,85) oraz Food and beverages (55,32).
  Odchylenie standardowe we wszystkich grupach jest bardzo podobne – waha się od 26,21 (Food
  and beverages) do 26,91 (Fashion accessories), co wskazuje na zbliżoną zmienność cen w każdej
  kategorii. Rozstęp międzykwartylowy (IQR) również pokazuje, że ceny w poszczególnych
  kategoriach nie różnią się znacznie pod względem rozproszenia – najwyższy IQR ma Health and
  beauty (47,92), a najniższy Food and beverages (43,21).
  Skośność we wszystkich przypadkach jest bliska zeru, co oznacza, że rozkłady cen są
  symetryczne – nie występuje wyraźne przesunięcie w stronę niższych lub wyższych wartości.
  Kurtoza we wszystkich kategoriach mieści się w przedziale 1,70–1,85, co oznacza, że rozkłady
  cen są lekko spłaszczone w porównaniu do rozkładu normalnego. Wskazuje to na mniejszą liczbę
  wartości skrajnych, czyli rzadziej występujące wyjątkowo niskie lub wysokie ceny.
</pre>

```{r statystyki_unit_price_wg_product_line}
statystyki_unit_price <- data %>%
  group_by(Product.line) %>%
  summarise(across(Unit.price, statystyki)) %>%
  unnest(cols = c(Unit.price))
```

```{r przeksztalcanie_tabele}
tabela_total <- statystyki_total %>%
  pivot_longer(cols = -Gender, names_to = "Statystyka", values_to = "Wartość") %>%
  pivot_wider(names_from = Gender, values_from = Wartość)

tabela_income <- statystyki_income %>%
  pivot_longer(cols = -Gender, names_to = "Statystyka", values_to = "Wartość") %>%
  pivot_wider(names_from = Gender, values_from = Wartość)

tabela_rating <- statystyki_rating %>%
  pivot_longer(cols = -Customer.type, names_to = "Statystyka", values_to = "Wartość") %>%
  pivot_wider(names_from = Customer.type, values_from = Wartość)

tabela_unit_price <- statystyki_unit_price %>%
  pivot_longer(cols = -Product.line, names_to = "Statystyka", values_to = "Wartość") %>%
  pivot_wider(names_from = Product.line, values_from = Wartość)
```

```{r tabele}
# Wyświetlenie tabel
knitr::kable(tabela_total,
             digits = 2,
             align = "lcc",
             caption = "Tabela 1. Statystyki dla 'Total' wg płci.",
             col.names = c("Statystyka", "Kobiety", "Mężczyźni"))

knitr::kable(tabela_income,
             digits = 2,
             align = "lcc",
             caption = "Tabela 2. Statystyki dla 'Gross Income' wg płci.",
             col.names = c("Statystyka", "Kobiety", "Mężczyźni"))

knitr::kable(tabela_rating,
             digits = 2,
             align = "lcc",
             caption = "Tabela 3. Statystyki dla 'Rating' wg typu klienta.",
             col.names = c("Statystyka", "Normal", "Member"))

knitr::kable(tabela_unit_price,
             digits = 2,
             align = "lcc",
             caption = "Tabela 4. Statystyki dla 'Unit Price' wg kategorii produktów.",
             col.names = c("Statystyka", unique(data$Product.line)))
```

# 8. Wykresy

<pre>
Wykres kołowy Na wykresie kołowym prezentuje preferencje metody płatności wezględu na płeć. Mężni wolą płacić karta debetową, kobiety preferują płatności gotówką.
</pre>

```{r setup8, include=FALSE }
# Podział danych według płci i metody płatności
gender_payment_counts <- data %>%
  group_by(Gender, Payment) %>%
  summarise(Count = n()) %>%
  mutate(Percentage = round((Count / sum(Count)) * 100, 1)) %>%
  ungroup()

# Tworzenie wykresu kołowego dla kobiet
plot_female <- ggplot(
  gender_payment_counts %>% filter(Gender == "Female"),
  aes(x = "", y = Percentage, fill = Payment)
) +
  geom_bar(stat = "identity", width = 1) +
  coord_polar("y", start = 0) +
  theme_void() +
  labs(title = "Metody płatności kobiet") +
  geom_text(aes(label = paste0(Percentage, "%")), position = position_stack(vjust = 0.5)) +
  scale_fill_brewer(palette = "Set3")

# Tworzenie wykresu kołowego dla mężczyzn
plot_male <- ggplot(
  gender_payment_counts %>% filter(Gender == "Male"),
  aes(x = "", y = Percentage, fill = Payment)
) +
  geom_bar(stat = "identity", width = 1) +
  coord_polar("y", start = 0) +
  theme_void() +
  labs(title = "Metody płatności mężczyzn") +
  geom_text(aes(label = paste0(Percentage, "%")), position = position_stack(vjust = 0.5)) +
  scale_fill_brewer(palette = "Set3")

# Wyświetlenie wykresów obok siebie
library(gridExtra)
grid.arrange(plot_female, plot_male, ncol = 2)
```

### Wykres Histogram i pudełkowy

<pre>
    Histogram przedstawia rozkład ocen w poszczególnych miastach, pokazując, jak często występują określone wartości ocen. Dzięki niemu możemy łatwo zauważyć ogólny kształt rozkładu, jego skośność oraz ewentualne wartości odstające. Z kolei wykres pudełkowy (boxplot) pozwala lepiej zobaczyć rozkład danych pod kątem ich mediany, kwartylów oraz wartości odstających. Środkowa linia w pudełku reprezentuje medianę ocen, a granice pudełka pokazują zakres między pierwszym a trzecim kwartylem. Wąsy wskazują wartości minimalne i maksymalne, pomijając odstające obserwacje, które są zaznaczone jako osobne punkty. Wykres pudełkowy ułatwia szybkie porównanie mediany ocen między różnymi miastami oraz identyfikację ewentualnych różnic w rozproszeniu danych.
</pre>

```{r histogram, inlude=FALSE}
# Wyświetlenie wykresów obok siebie

grid.arrange(plot_female, plot_male, ncol = 2)

# Oddzielne histogramy dla każdego miasta
ggplot(data, aes(x = Rating)) +
  geom_histogram(bins = 30, fill = "#69b3a2", color = "black", alpha = 0.8) +
  facet_wrap(~ City, scales = "free_y") +  # Oddzielne panele dla każdego miasta
  labs(
    title = "Rozkład ocen (Rating) w zależności od miasta",
    x = "Ocena (Rating)",
    y = "Liczba obserwacji"
  ) +
  theme_minimal() +
  theme(
    strip.text = element_text(size = 12, face = "bold"),  # Wyraźne etykiety miast
    axis.text = element_text(size = 10),
    axis.title = element_text(size = 12)
  )
# Rozkład dla oceny 
ggplot(data, aes(x = City, y = Rating, fill = City)) +
  geom_boxplot(alpha = 0.8) +
  labs(
    title = "Porównanie ocen (Rating) w zależności od miasta",
    x = "Miasto",
    y = "Ocena (Rating)",
    fill = "Miasto"
  ) +
  theme_minimal() +
  scale_fill_brewer(palette = "Pastel1")
```

### Wykres słópkowy

<pre>
    Wykres słupkowy przedstawia średnią sprzedaż dla każdej linii produktów, co pozwala na szybkie porównanie wyników poszczególnych kategorii. Słupki mają kolor niebieski, a ich wysokość odpowiada wartości średniej sprzedaży w danej linii produktów.
</pre>

```{r wykres słópkowy, inlude=FALSE}
# Tworzenie wykresu słópkowego 
# Obliczanie średniej sprzedaży dla każdej linii produktów
average_sales <- aggregate(Total ~ Product.line, data = data, mean)

# Zwiększenie marginesów dla większej przestrzeni na etykiety
par(mar = c(8, 4, 4, 2) + 0.1)

# Tworzenie wykresu słupkowego z bardziej czytelnymi etykietami
barplot(
  average_sales$Total, 
  names.arg = average_sales$Product.line, 
  col = "lightblue",  # Kolor słupków
  main = "Średnia sprzedaż według linii produktów", 
  xlab = "",          # Usuń opis osi X, aby nie dublować etykiet
  ylab = "Średnia sprzedaż",
  las = 2,            # Pionowe etykiety osi X
  cex.names = 0.6     # Zmniejszenie rozmiaru tekstu etykiet
)

# Dodanie opisu osi X poniżej wykresu
mtext("Linia produktów", side = 1, line = 7, cex = 1.2)
```

### Wykres heatmapa

<pre>
    Wykres typu heatmapa przedstawia średnie oceny (Rating) w zależności od miasta i płci. Kolor kafelków odzwierciedla wartość średniej oceny – jaśniejsze odcienie oznaczają niższe wartości, a ciemniejsze wyższe
</pre>

```{r setup9, inlude=FALSE}
# Agregowanie danych
heatmap_data <- data %>%
  group_by(City, Gender) %>%
  summarise(Average_Rating = mean(Rating, na.rm = TRUE)) %>%
  ungroup()

# Tworzenie wykresu
ggplot(heatmap_data, aes(x = Gender, y = City, fill = Average_Rating)) +
  geom_tile(color = "white") +
  labs(
    title = "Średnie oceny (Rating) w zależności od miasta i płci",
    x = "Płeć",
    y = "Miasto",
    fill = "Średnia ocena"
  ) +
  theme_minimal() +
  scale_fill_gradient(low = "lightblue", high = "darkblue")

```

### Wykres linowy

<pre>
    Wykres liniowy przedstawia trend sprzedaży w czasie, umożliwiając obserwację zmian w całkowitej sprzedaży na przestrzeni dni. Linia łączy punkty reprezentujące dzienne sumy sprzedaży, co pozwala na łatwe dostrzeżenie wzorców, takich jak okresowe wzrosty i spadki.
</pre>

```{r wykres linowy, inlude=FALSE}
# Tworzenie wykresu trendów 
# Konwersja kolumny 'Date' na format daty
data$Date <- as.Date(data$Date, format = "%m/%d/%Y")

# Grupowanie danych według daty i obliczanie całkowitej sprzedaży
daily_sales <- aggregate(Total ~ Date, data = data, sum)

# Tworzenie wykresu liniowego
plot(
  daily_sales$Date, 
  daily_sales$Total, 
  type = "l",             # Typ wykresu: linia
  col = "blue",           # Kolor linii
  lwd = 2,                # Grubość linii
  main = "Sprzedaż w czasie", 
  xlab = "Data", 
  ylab = "Całkowita sprzedaż"
)

# Dodanie punktów na wykresie dla lepszej widoczności
points(
  daily_sales$Date, 
  daily_sales$Total, 
  col = "black",            # Kolor punktów
  pch = 16                # Typ punktów: kropki
)
```

### Porównanie 'Total' i 'Branch'

<pre>
  Wykres pudełkowy przedstawia porównanie wartości 'Total' dla trzech gałęzi (A, B, C). Każda
  gałąź ma podobny rozkład wartości, z medianą na zbliżonym poziomie. Występują wartości
  odstające (outliers) powyżej 1000. Rozstęp międzykwartylowy (IQR) jest podobny dla wszystkich
  gałęzi, co sugeruje względnie równomierne rozproszenie danych.
</pre>

```{r porownanie_total_branch}
# Porównanie Total wg gałęzi
ggplot(data, aes(x = Branch, y = Total, fill = Branch)) +
  geom_boxplot() +
  labs(title = "Porównanie 'Total' wg gałęzi", x = "Gałęzie", y = "Total")
```

### Rozkład 'gross income' i 'customer type'

<pre>
  Większość transakcji generuje niskie wartości Gross Income (głównie poniżej 10), co widać po
  wysokich słupkach na początku osi X.
  Rozkład jest prawostronnie skośny – im wyższy Gross Income, tym rzadsze transakcje.
  Klienci Normal (turkusowy kolor) mają więcej transakcji o niższych wartościach Gross Income,
  ale ich rozkład jest zbliżony do członków Member (czerwony kolor).
</pre>

```{r rozklad_gross_income_customer_type}
ggplot(data, aes(x = gross.income, fill = Customer.type)) +
  geom_histogram(bins = 20, alpha = 0.7, position = "identity") +
  labs(title = "Rozkład 'Gross Income' wg typu klienta", x = "Gross Income", y = "Liczba transakcji")
```

### Rozkład 'rating' wg płci

<pre>
  Wykres przedstawia rozkład ocen w zależności od płci (Female – czerwony, Male – turkusowy).
  Ogólny rozkład ocen dla obu płci jest podobny, ale są pewne różnice w gęstości.
  Mężczyźni (turkusowy) mają większą koncentrację ocen wokół 6-7, co oznacza, że częściej
  wystawiają oceny w tym zakresie.
  Kobiety (czerwony) mają więcej ocen w skrajnych wartościach – widoczny jest nieco większy
  udział ocen w okolicach 4-5 oraz 9-10.
  Ogólnie, różnice nie są duże, ale kobiety częściej wystawiają zarówno bardzo niskie, jak i
  bardzo wysokie oceny, a mężczyźni częściej oceniają w średnim zakresie.
</pre>

```{r rozklad_rating_gender}
ggplot(data, aes(x = Rating, fill = Gender)) +
  geom_density(alpha = 0.5) +
  labs(title = "Rozkład ocen wg płci", x = "Ocena", y = "Gęstość")
```

### Porównanie 'gross income' i płci

<pre>
  Wykres przedstawia porównanie dochodów brutto ze względu na płeć. Mediana dochodów kobiet i
  mężczyzn jest na zbliżonym poziomie, co sugeruje brak istotnych różnic w przeciętnych
  zarobkach między grupami. Rozkład dochodów w obu przypadkach jest podobny, choć widać kilka
  wartości odstających, wskazujących na jednostki z wyraźnie wyższymi zarobkami. 
  Ogólnie dochody obu płci mają porównywalną strukturę.
</pre>

```{r porownanie_gross_income_gender}
ggplot(data, aes(x = Gender, y = gross.income, fill = Gender)) +
  geom_boxplot() +
  labs(title = "Gross Income wg płci", x = "Płeć", y = "Gross Income")
```

### Porównanie 'customer type' i 'total'

<pre>
  Wykres przedstawia porównanie całkowitej wartości zakupów w zależności od typu klienta.
  Mediana wydatków dla członków programu lojalnościowego (Member) i klientów standardowych
  (Normal) jest na podobnym poziomie, co sugeruje brak istotnych różnic w przeciętnych
  wartościach zakupów. Rozkład wydatków jest zbliżony dla obu grup, choć występują pojedyncze
  wartości odstające wskazujące na wyjątkowo wysokie zakupy. 
  Ogólnie rzecz biorąc, typ klienta nie wydaje się mieć dużego wpływu na poziom wydatków.
</pre>

```{r porownanie_customer_type_total}
ggplot(data, aes(x = Customer.type, y = Total, fill = Customer.type)) +
  geom_boxplot() +
  labs(title = "Total wg typu klienta", x = "Typ klienta", y = "Total")
```

### Porównanie 'rating' i 'branch'

<pre>
  Wykres przedstawia porównanie ocen (Rating) dla trzech różnych gałęzi (A, B, C). Mediany ocen
  we wszystkich gałęziach są zbliżone, co sugeruje, że poziom ocen klientów jest podobny
  niezależnie od oddziału. Rozkład ocen jest szeroki, co oznacza, że w każdej gałęzi występują
  zarówno niskie, jak i wysokie oceny. 
  Ogólnie rzecz biorąc, nie widać znaczących różnic w ocenach między oddziałami.
</pre>

```{r porownanie_rating_branch}
ggplot(data, aes(x = Branch, y = Rating, fill = Branch)) +
  geom_boxplot() +
  labs(title = "Porównanie 'Rating' wg gałęzi", x = "Gałęzie", y = "Rating")
```

### Porównanie 'gross income' i 'product line'

<pre>
  Wykres przedstawia porównanie dochodu brutto ("Gross Income") w różnych kategoriach
  produktów. 
  Większość kategorii produktów ma podobną medianę wartości dochodu brutto, co sugeruje, że
  przeciętny dochód dla różnych typów produktów jest zbliżony. Szerokość pudełek jest podobna w
  większości kategorii, co oznacza porównywalną zmienność danych. W każdej kategorii występują
  wartości odstające, co sugeruje, że w niektórych przypadkach dochód brutto był wyjątkowo
  wysoki.
  Ogólnie rzecz biorąc, różnice między kategoriami produktów nie są znaczące, co sugeruje, że
  żadna z nich nie wyróżnia się wyraźnie pod względem dochodu brutto.
</pre>

```{r porownanie_gross_income_product_line}
ggplot(data, aes(x = Product.line, y = gross.income, fill = Product.line)) +
  geom_boxplot() +
  labs(title = "Porównanie 'Gross Income' wg kategorii produktów", x = "Kategoria produktu", y = "Gross Income") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

# 9. Wnioskowanie statystyczne.

<pre>
    Końcowa analiza zbioru danych dotyczącego sprzedaży w trzech sklepach Biedronka polega na przeprowadzeniu
testów parametrycznych i nieparametrycznych w celu zrozumienia określonych wartości zmiennych.

    Zmienne ilościowe brane pod uwagę przy testowaniu to: 'Rating', Unit.price', 'Quantity' i 'Total', natomiast 
zmienne kategoryczne to: 'City', 'Customer.type' i 'Payment'.
</pre>

### Testowanie normalności rozkładów

<pre>
    Testowanie normalności rozkładów zmiennych opiera się na statystyce Shapiro-Wilka oraz wykresie Q-Q 
(<em>Quantile-Quantile</em>), porównującym rozkład empiryczny danej zmiennej z rozkładem normalnym.

    Hipotezy dla testu Shapiro-Wilka brzmią następująco:
    
    H0: <em>Badana zmienna posiada rozkład normalny wartości.</em>
    HA: <em>Badana zmienna nie posiada rozkładu normalnego wartości.</em>
</pre>

#### \* Zmienna 'Rating'\*

```{r Testy normalności - Rating, echo=FALSE}
shapiro_test1 <- shapiro.test(data$Rating)
results4 <- data.frame(
  Statystyka = round(shapiro_test1$statistic, 2),
  p_value = round(shapiro_test1$p.value, 2))

results4 %>%
  kable("html", caption = "Test Shapiro-Wilka", align = 'c') %>%
  kable_styling(
    bootstrap_options = c("striped", "hover", "condensed", "responsive"),
    full_width = FALSE,
    html_font = "Arial",
    font_size = 14)

```

#### *Zmienna 'Unit.price'*

```{r Testy normalności - Unit.price, echo=FALSE}
shapiro_test2 <- shapiro.test(data$Unit.price)
results5 <- data.frame(
  Statystyka = round(shapiro_test2$statistic, 2),
  p_value = round(shapiro_test2$p.value, 2))

results5 %>%
  kable("html", caption = "Test Shapiro-Wilka", align = 'c') %>%
  kable_styling(
    bootstrap_options = c("striped", "hover", "condensed", "responsive"),
    full_width = FALSE,
    html_font = "Arial",
    font_size = 14)



```

#### *\> Zmienna 'Quantity'*

```{r Testy normalności - Quantity, echo=FALSE}
shapiro_test3 <- shapiro.test(data$Quantity)
results6 <- data.frame(
  Statystyka = round(shapiro_test3$statistic, 2),
  p_value = round(shapiro_test3$p.value, 2))

results6 %>%
  kable("html", caption = "Test Shapiro-Wilka", align = 'c') %>%
  kable_styling(
    bootstrap_options = c("striped", "hover", "condensed", "responsive"),
    full_width = FALSE,
    html_font = "Arial",
    font_size = 14)


```

#### *\> Zmienna 'Total'*

```{r Testy normalności - Total, echo=FALSE}
shapiro_test4 <- shapiro.test(data$Total)
results7 <- data.frame(
  Statystyka = round(shapiro_test4$statistic, 2),
  p_value = round(shapiro_test4$p.value, 2))

results7 %>%
  kable("html", caption = "Test Shapiro-Wilka", align = 'c') %>%
  kable_styling(
    bootstrap_options = c("striped", "hover", "condensed", "responsive"),
    full_width = FALSE,
    html_font = "Arial",
    font_size = 14)


```

<pre>
    Testy normalności rozkładów zmiennych: 'Rating', 'Unit.price', 'Quantity' oraz 'Total' wykazały, że są to zmienne
nie posiadające rozkładów normalnych swoich wartości. 
    Wniosek ten uzasadnia statystyka Shapiro-Wilka, która w przypadku każdej zmiennej wyniosła ok. `r mean(.96,.65,.93,.91)`,
a odpowiadająca jej wartość p-value przyjęła wartość niższą od przyjętego poziomu istotności (0 < 0,05), czym 
wykazała, że istnieją przesłanki, aby odrzucić H0 mówiącą o normalności rozkładu wartości badanych zmiennych.
    Ponadto wykresy Q-Q dla wymienionych zmiennych nie przyjęły postaci linii prostej, znacznie odchylając się od 
rozkładu normalnego, czym również przyczyniły się do wsparcia hipotezy o braku rozkładu normalnego zmiennych 
'Rating', 'Unit.price', 'Quantity' oraz 'Total'.

    Wobec powyższego przyjmuje się, że dalsze analizowanie zmiennych opierać się będzie o testy nieparametryczne.
</pre>

### Testy nieparametryczne dla wybranych zmiennych ilościowych i kategorycznych

#### Histogramy i test Wilcoxona

```{r Test nieparametryczny dla Total, echo=FALSE, message=FALSE, warning=FALSE}
gghistostats(
  data       = data,
  x          = Rating,
  title      = "Ocena placówki",
  type = "np",
  test.value = 5.5,
  binwidth   = 1
) +
scale_x_continuous(limits = c(1, 10), breaks = seq(1, 10, by = 1))

gghistostats(
  data       = data,
  x          = Unit.price,
  title      = "Cena jednostkowa towaru",
  type = "np",
  test.value = 55.23,
  binwidth   = 1
)

gghistostats(
  data       = data,
  x          = Quantity,
  title      = "Liczba zakupionych towarów",
  type = "np",
  test.value = 5,
  binwidth   = 1
)


gghistostats(
  data = data.frame(data),
  x = Total,
  title      = "Całkowita cena zakupu z 5% podatkiem",
  type = "np",
  normal.curve = TRUE,
  test.value = 253.85,
  binwidth = 5
)
```

<pre>
Przedstatwione wyżej histogramy dla wybranych zmiennych ilościowych wykazały, że:
  - rozkład wartości dla zmiennej 'Rating' jest lewostronnie skośny, gdyż większość wartości skupia się po prawej
    stronie od mediany równej `r median(1:10)`. Ponadto najczęściej przyznawaną oceną dla sklepu było 6 (17,5%
    klientów), a najrzadsze oceny miały zakres 1-3,9 (0% klientów).
  - rozkład wartości dla zmiennej 'Unit.price' nie wykazuje obserwowalnego skupienia po którejś ze stron mediany
    równej 55,23. Oznacza to, że ceny produktów były mniej więcej podobne, istnieją jednak pojedyncze odstępstwa
    od tych wartości;
  - rozkład wartości dla zmiennej 'Quantity' jest nieznacznie prawostronnie skośny od mediany równej 5, co świadczyć
    może, że zwyczajowa liczba produktów kupowana przez badanych klientów była większa niż 5. Ponadto największa
    liczba klientów (ok. 11,5%) kupowała 10 sztuk towaru w danej lokalizacji i czasie;
  - rozkład wartości dla zmiennej 'Total' jest prawostronnie skośny, o czym świadczy fakt, że wartości rozciągają się
    po prawej stronie od mediany równej 253,85, a większość wartości koncentruje się po jej lewej stornie. Stwierdzić
    zatem można, że największa liczba transakcji opiewała na kwoty z przedziału ok. 0-250 dolarów, gdyż wartości
    w przedziale 0-250 dolarów dominują, ale pojawiają się również wartości dochodzące do 1050 dolarów, co ma
    wpływ na końcową skośność. 
    
    Ponadto statystyka Wilcoxona, dla której testowane są hipotezy:
    
    H0: <em>Rozkład wartości zmiennej nie różni się od mediany jej wartości,</em>
    HA: <em>Rozkład wartości zmiennej różni się od mediany jej wartości,</em>
    
    wykazała, że na podstawie wartości p-value, która jest bliska 0 dla wszystkich zmiennych (p-value < 0,05) można
odrzucić H0 mówiące o braku różnic między wartościami zmiennych, a ich medianą.
</pre>

#### Testy zależności

##### *\> Testy zależności dla zmiennej 'Rating'*

```{r Testy zależności - Rating1, echo=FALSE, fig.show='hold'}
ggbetweenstats(
  data=data,
  y=Rating,
  x=City,
  type="np")
```

<pre>
Dla nieparametrycznego testu Kruskala-Wallisa zależności bada się następujące hipotezy:

    H0: <em>Rozkład wartości zmiennej ocen ('Rating') w każdym mieście ('City') jest taki sam.</em>
    HA: <em>Rozkład wartości zmiennej ocen ('Rating') w każdym mieście ('City') nie jest taki sam.</em>
    
    Statystyka testu wyniosła 1,86 przy wartości p-value większej od przyjętego poziomu istotności alfa (0,39 > 0,05), 
co wskazuje, że nie ma istotnych przesłanek do odrzucenia H0, twierdzącego, że rozkłady wartości ocen we wszystkich 
trzech miastach, gdzie znajdują się sklepy są sobie równe.
</pre>

```{r Testy zależności - Rating2, echo=FALSE, fig.show='hold'}
ggbetweenstats(
  data=data,
  y=Rating,
  x=Customer.type,
  type="np")
```

<pre>
Dla nieparametrycznego testu zależności Manna-Whitneya między zmienną 'Rating' a 'Customer.type' bada się hipotezy:

    H0: <em>Mediany ocen ('Rating') nadawanych przez oba typy klientów ('Customer.type') są sobie równe, a rozkłady 
           dla klienta "Member" i "Normal" są identyczne.</em>
    HA: <em>Mediany ocen ('Rating') nadawanych przez oba typy klientów ('Customer.type') nie są sobie równe, 
            a rozkłady dla klienta "Member" i "Normal" są nie identyczne.</em>
        HA1: <em>Mediana ocen ('Rating') nadawanych przez posiadaczy karty członkowskiej jest większa od mediany ocen
                 osób nieposiadających karty.</em>
        HA2: <em>Mediana ocen ('Rating') nadawanych przez posiadaczy karty członkowskiej jest mniejsza od mediany 
                 ocen osób nieposiadających karty.</em>
    
    Statystyka testu wyniosła ok. 119 000 przy wartości p-value większej od przyjętego poziomu istotności alfa
(0,2 > 0,05), co wskazuje, że nie ma istotnych przesłanek do odrzucenia H0 twierdzącego, że mediany wartości ocen 
nadawanych przez osobę posiadającą kartę członkowską nie różnią się znacząco od mediany ocen przyznawanych 
przez klientów nie będących w jej posiadaniu. Ponadto test wykazał, że rozkłady dla obu typów klientów są z dużym 
prawdopodobieństwem identyczne.
</pre>

#### *Testy zależności zmiennej 'Quantity' oraz 'Gender'*

```{r Testy zależności zmiennej Quantity oraz Gender, echo=FALSE}
ggbetweenstats(
  data=data,
  y=Quantity,
  x=Gender,
  type="np")
```

<pre>
Dla nieparametrycznego testu zależności Manna-Whitneya zmiennej 'Gender' i 'Quantity' bada się hipotezy:

    H0: <em>Mediany ilości zakupionych produktów ('Quantity') przez klientów obu płci ('Customer.type') są sobie
            równe i rozkłady dla "Female" i "Male" są identyczne.</em>
    HA: <em>Mediany ilości zakupionych produktów ('Quantity') przez klientów obu płci ('Customer.type') nie są sobie 
            równe i rozkłady dla "Female" i "Male" nie są identyczne.</em>
        HA1: <em>Mediana ilości zakupionych produktów ('Quantity') przez kobiety ("Female") jest większa od
                 mediany ilości towarów dla mężczyzn ("Male").</em>
        HA2: <em>Mediana ilości zakupionych produktów ('Quantity') przez kobiety ("Female") jest mniejsza od
                 mediany ilości towarów dla mężczyzn ("Male").</em>
Statystyka testu wyniosła ok. 136 000 przy wartości p-value mniejszej od przyjętego poziomu istotności alfa 
(0,2 < 0,05), co wskazuje, że istnieją istotne przesłanki, aby odrzucić H0 twierdzącą, że mediany ilości produktów 
zakupionych przez klientów obu płci są sobie równe, a rozkład wartości ilości zakupionych produktów dla kobiet 
i mężczyzn są identyczne. Ponadto stwierdzić można, że mediana ilości zakupionych towarów kobiet jest większa 
od mediany dla mężczyzn.
</pre>

#### *Test korelacji między zmiennymi 'Customer.type' i 'Payment'*

```{r Korelacja między Customer.type i Payment, echo=FALSE}
ggbarstats(
  data=data,
  y=Customer.type,
  x=Payment,
  typr = "np")
```

<pre>
    Dla nieparametrycznego testu Pearsona (p) badającego korelację między zmiennymi 'Customer.type' i 'Payment'
bada się następujące hipotezy:

    H0: <em>Nie istnieje korelacja między osobami posiadającymi i nieposiadającymi kartę członkowską sklepu a formą 
           płatności za zakupy (p = 0).</em>
    HA: <em>Istnieje korelacja między osobami posiadającymi i nieposiadającymi kartę członkowską sklepu a formą 
           płatności za zakupy (p =/= 0).</em>
    
    Statystyka testu Pearsona (p) wyniosła 5,22 przy wartości p-value mniejszej od przyjętego poziomu istotności alfa
(0,03 < 0,05) dla osoby nie będącej posiadaczem karty lojalnosciowej sklepu i większej dla osoby, która tę kartę ma
(0,83 > 0,05). W związku z tym dla osoby nie posiadającej karty, istnieją istotne przesłanki, aby odrzucić H0, a co 
za tym idzie - jej korelacja z formą płatności istnieje i jest dodatnia (p > 0), natomiast dla osoby posiadającej taką
kartę nie ma podstaw do odrzucenia H0, zatem jej korelacja z formą płatności nie występuje.
</pre>

### PODSUMOWANIE CZĘŚCI TESTOWEJ

<pre>
Przeprowadzone testy wykazały następujące zależności:
  - Ocena klientów ('Rating') nigdy nie była niższa od oceny 4, natomiast najczęściej przyznawana ocena przez
    klientów to 6. Ponadto prawdopodobnym jest, że przyznawane oceny nie są zależne ani od miasta, w jakim się
    znajduje dany sklep Biedronka, ani od faktu, czy klient posiada kartę lojalnościową czy też nie.
  - Ilość zakupionych produktów 'Quantity' przez przeciętnego, badanego klienta w trzech pierwszych miesiącach 2019
    wynosiła więcej niż 5. Ponadto środkowa liczba oznaczająca ilość zakupionych produktów przez kobiety była w tym
    okresie wyższa od mediany zakupionych produktów przez mężczyzn.
  - Istnieje pewna zależność pomiędzy osobami nieposiadającymi kartę członkowską sklepu a formą, jaką wybierają
    przy płatności za zakupy. Można się spodziewać, że takie osoby częściej wybiorą płatność poprzez portfel
    elektroniczny niż kartą kredytową czy gotówką. Dodatkowo płatność kartą kredytową wybiorą najmniej chętnie.
    Nie istnieją jednak przesłanki, aby móc zakładać, że osoby posiadające kartę członkowską preferują daną formę
    płatności za zakupy.
</pre>
